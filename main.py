from game.game import Game
from agent.snake_agent import Agent
from utils.helpers import plot, open_file
import argparse as ap


FPS = 1000


def print_plot(game, total_size):
    size.append(len(game.snake.body))
    total_size += len(game.snake.body)
    mean_size.append(total_size / episode)
    plot(size, mean_size)
    return total_size


if __name__ == '__main__':
    # Flags
    parser = ap.ArgumentParser()
    parser.add_argument("-s", "--size", help="size", type=int, default=10)
    parser.add_argument("-n", "--training_session", help="Training_session(s)",
                        type=int, default=1000)
    parser.add_argument("-e", "--epsilon", help="No learning",
                        action='store_false')
    parser.add_argument("-L", "--learning", help='Update agent',
                        action='store_false')
    parser.add_argument("-D", "--display", help="Display off",
                        action="store_false")
    parser.add_argument("-load_f", "--path",
                        help="Load a file with training informations",
                        type=str, default=None)
    parser.add_argument("-v", "--vision", help="Print snake vision",
                        action="store_true")
    args = parser.parse_args()

    try:
        if (args.path):
            file = open_file(args.path)
    except Exception as e:
        print(e)

    agent = Agent(args.training_session, args.epsilon, args.learning, args.path)
    total_size = 0
    size = []
    mean_size = []
    for episode in range(1, agent.episodes):
        game = Game(args.size, args.display)
        if args.vision:
            print(game.snake.get_vision(game.board))
        while game.running:
            agent.state = game.get_state()
            game.handle_input(agent.choose_action(game))
            agent.reward = game.update()
            if game.snake.body:
                agent.new_state = game.get_state()
            agent.update_q_table()
            game.draw()
            game.clock.tick(FPS)
        agent.update_epsilon()
        total_size = print_plot(game, total_size)
    agent.save_q_table()


# TODO Step-bt-step Mode ðŸš§
# TODO state segfault quand meurt de pomme rouge / Maybe Done with if in main âœ…
# TODO Vision matrix // DONE âœ…
# TODO Flags ðŸš§
# TODO Use the q-table from a file/ Non random move then ðŸš§
# TODO Flags Number of training session âœ…/ don't learn âœ…/ Visual display âœ…
# load file / epsilon 0 âœ…
# TODO one Game object for the loop

# TODO Bonus: modifiable board Size âœ… Implement draw function ðŸš§
# TODO Accurcy of the bot
# TODO Neural network Agent
# TODO Norme FLAKE8
